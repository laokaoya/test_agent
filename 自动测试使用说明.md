# 🔄 自动循环测试功能说明

## 📖 功能概述

自动循环测试功能允许系统**持续不断地运行测试**，每完成一轮测试后自动开始下一轮，直到用户手动停止。

### ✨ 核心特性

1. **无限循环**：测试完成后自动开始新一轮
2. **自动保存**：每轮测试结果自动保存到CSV和JSON
3. **新对话ID**：每轮测试都使用全新的`conversation_id`
4. **实时统计**：显示已完成测试次数和运行时间
5. **随时暂停**：可以随时停止自动测试

---

## 🎮 使用方法

### 1️⃣ **启动自动测试**

1. 在左侧配置面板设置好：
   - 角色信息（名字、年龄、特征、开场白）
   - 评分标准（选择或自定义）
   - 对话轮数（默认3轮）
   - API密钥（如需自定义）

2. 点击 **"🔄 自动循环测试"** 按钮

3. 确认弹窗提示

4. 系统开始运行：
   - 显示"自动测试统计"面板
   - 开始第一轮测试
   - 测试完成后自动进入第二轮...

### 2️⃣ **监控测试状态**

自动测试运行时，左侧会显示统计信息：

```
📊 自动测试统计
━━━━━━━━━━━━━━━━━━
已完成测试：5 次
运行时间：00:15:42
当前状态：运行中
```

- **已完成测试**：已完成的完整测试轮数
- **运行时间**：从启动到现在的总时间（HH:MM:SS）
- **当前状态**：运行中 / 已停止

### 3️⃣ **停止自动测试**

点击 **"⏸️ 暂停自动测试"** 按钮：
- 当前正在进行的测试会完成
- 不会开始新的测试轮次
- 统计信息显示"已停止"
- 3秒后统计面板自动隐藏

---

## 🔍 工作原理

### 测试流程

```
[开始自动测试]
     ↓
[第1轮测试]
 ├─ 角色1 (3轮对话, conversation_id_1)
 ├─ 角色2 (3轮对话, conversation_id_2)
 └─ ...
     ↓
[评分并保存]
     ↓
[等待1秒]
     ↓
[第2轮测试]
 ├─ 角色1 (3轮对话, conversation_id_3) ← 新ID
 ├─ 角色2 (3轮对话, conversation_id_4) ← 新ID
 └─ ...
     ↓
[评分并保存]
     ↓
[继续循环...]
```

### 关键机制

1. **Conversation ID 管理**
   - 每次调用`runRealTimeTest()`时，`conversationId`初始化为`null`
   - Dify API返回新的`conversation_id`
   - 保证每轮测试都是独立的对话会话

2. **自动循环逻辑**
   ```javascript
   // 在runTest()函数末尾
   if (isAutoTestRunning) {
       autoTestCount++;
       setTimeout(() => {
           if (isAutoTestRunning) {
               runTest();  // 递归调用
           }
       }, 1000);
   }
   ```

3. **数据持续保存**
   - 每轮测试完成后自动调用`/api/save-result`
   - CSV追加写入新行
   - JSON追加新测试记录

---

## 📊 数据记录

### 文件存储

**CSV文件**（`test_results.csv`）
- 每轮测试追加一行
- 包含完整的测试信息和评分

**JSON文件**（`test_results.json`）
- 每轮测试追加一个JSON对象
- 结构化存储，便于程序读取

### 数据结构

每轮测试记录包含：
- **测试ID**：唯一标识（时间戳 + 角色名）
- **角色信息**：名称、年龄、类型、特征
- **对话内容**：所有轮次的完整对话（JSON格式）
- **评分结果**：各项评分、平均分、标准差
- **评价内容**：评分理由、经验教训、角色自述
- **统计数据**：字数统计、时间戳等

---

## 💡 使用场景

### 1. **压力测试**
```
目的：测试AI系统的稳定性
设置：3-5个不同角色，每轮5次对话
运行：自动测试12小时
分析：检查响应时间、错误率、对话质量趋势
```

### 2. **数据收集**
```
目的：收集大量对话样本用于分析
设置：多个典型儿童角色
运行：自动测试收集100轮以上数据
分析：统计分析AI表现模式
```

### 3. **A/B测试**
```
目的：对比不同prompt效果
方法：
  - 第一批自动测试使用Prompt A
  - 修改Dify配置
  - 第二批自动测试使用Prompt B
分析：对比两批测试的评分差异
```

### 4. **夜间批量测试**
```
目的：利用非工作时间进行测试
操作：下班前启动自动测试
时间：运行一整夜
次日：分析大量测试数据
```

---

## ⚠️ 注意事项

### API配额管理

**Dify API**
- 注意API调用配额限制
- 每轮测试 = 角色数 × 对话轮数 次调用
- 例：3个角色，3轮对话 = 9次API调用/轮

**Gemini API**
- 每轮测试需要调用Gemini：
  - 生成儿童回复（每轮对话1次）
  - 最终评分（每个角色1次）
- 例：3个角色，3轮对话 = 9次生成 + 3次评分 = 12次调用/轮

### 费用估算

假设自动测试24小时：
```
配置：3个角色，3轮对话，每轮约3分钟
24小时测试轮数：480轮
API调用次数：
  - Dify: 480 × 9 = 4,320次
  - Gemini: 480 × 12 = 5,760次
```

**建议**：
1. 先运行1小时测试，观察API消耗
2. 根据配额合理设置运行时间
3. 使用自定义API密钥分散调用

### 系统资源

- **浏览器性能**：长时间运行可能导致浏览器变慢
  - 建议定期刷新页面（会自动停止测试）
  - 或使用无头浏览器模式

- **磁盘空间**：
  - CSV和JSON文件会持续增长
  - 每轮测试约2-5KB数据
  - 1000轮测试约2-5MB

### 测试中断

如果需要临时中断：
1. 点击"暂停自动测试"
2. 当前测试轮会完成
3. 数据已保存，可以随时继续

如果浏览器意外关闭：
- 已完成的测试数据已保存
- 重新打开页面可以继续测试
- 统计数据（轮数、时间）会重置

---

## 🔧 高级技巧

### 1. **批量角色测试**

可以添加多个角色，系统会依次测试：
```
角色1: 害羞型小孩
角色2: 话多型小孩
角色3: 好奇型小孩
...
```
每轮测试会按顺序测试所有角色。

### 2. **动态调整配置**

在测试暂停时可以：
- 修改角色设定
- 调整评分标准
- 更换API密钥
- 改变对话轮数

### 3. **数据分析脚本**

可以编写Python脚本读取JSON数据进行分析：
```python
import json
import pandas as pd

# 读取JSON数据
with open('test_results.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# 转换为DataFrame
df = pd.json_normalize(data)

# 分析平均分趋势
df['scores.average'].plot()

# 按角色类型分组
df.groupby('child.type')['scores.average'].mean()
```

---

## 🎯 最佳实践

1. **小范围试运行**
   - 先运行5-10轮测试
   - 检查数据记录是否正常
   - 确认API调用成功

2. **合理设置轮数**
   - 测试质量：3-5轮对话
   - 快速收集：2-3轮对话
   - 深度测试：5-10轮对话

3. **定期检查结果**
   - 每小时查看一次测试进度
   - 检查评分是否合理
   - 观察有无异常错误

4. **备份数据**
   - 定期备份CSV和JSON文件
   - 避免数据丢失

5. **错误处理**
   - 如果发现API错误，及时暂停
   - 检查日志（浏览器控制台）
   - 修复问题后重新启动

---

## 📞 故障排查

### 问题：自动测试没有继续下一轮

**可能原因：**
- JavaScript错误导致循环中断
- API调用失败

**解决方法：**
1. 打开浏览器控制台（F12）查看错误
2. 检查网络请求是否成功
3. 重新启动自动测试

### 问题：数据没有保存

**可能原因：**
- `/api/save-result`调用失败
- 文件写入权限问题

**解决方法：**
1. 检查Flask终端日志
2. 查看`test_results.csv`和`test_results.json`是否更新
3. 检查文件权限

### 问题：对话内容重复

**可能原因：**
- `conversation_id`没有重置
- Dify缓存问题

**解决方法：**
1. 检查终端日志中的`conversation_id`
2. 确认每次都是新的ID
3. 清空Dify对话历史（如适用）

---

## 🚀 快速开始示例

### 示例1：简单压力测试

```
配置：
- 角色：默认第一个预设角色（小熊）
- 标准：前三个预设标准
- 轮数：3轮
- API：使用默认密钥

操作：
1. 打开页面（已自动加载默认配置）
2. 点击"自动循环测试"
3. 确认开始
4. 运行30分钟
5. 点击"暂停"
6. 查看CSV数据
```

### 示例2：多角色对比测试

```
配置：
- 添加5个内置角色（害羞、话多、好奇、自信、抗拒）
- 使用全部13个预设标准
- 轮数：5轮
- API：自定义Gemini密钥（避免配额）

操作：
1. 添加5个预设角色
2. 添加所有预设标准
3. 在"设置"中填入自定义API密钥
4. 设置对话轮数为5
5. 启动自动测试
6. 运行2小时
7. 暂停并分析数据
```

---

## 📝 更新日志

**v1.0** (2025-10-18)
- ✨ 新增自动循环测试功能
- ✨ 新增实时统计面板
- ✨ 新增运行时间计时器
- ✨ 每轮测试自动重置conversation_id
- ✨ 数据持续保存到CSV和JSON
- ✨ 支持随时暂停和恢复

---

## 🎉 总结

自动循环测试功能让您可以：
- 🔄 **无人值守**运行大量测试
- 📊 **自动记录**所有测试数据
- 🎯 **灵活配置**角色和标准
- ⏸️ **随时控制**启动和停止

非常适合用于AI系统的**压力测试**、**数据收集**和**性能分析**！

开始使用吧！🚀

