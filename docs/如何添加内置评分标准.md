# 📊 如何添加内置评分标准

## 🎯 概述

所有内置评分标准的配置都存储在 `preset_criteria.json` 文件中。要添加新的评分标准，只需编辑这个文件即可，无需修改代码。

**⚠️ 重要提示：评分标准是评价AI的表现，而不是评价孩子！**

评分目的：
- 测评AI是否能很好地实现教学目标
- 测评AI是否能有效陪伴孩子
- 测评AI是否能引起孩子兴趣
- 测评AI的互动质量和引导能力

## 📝 添加新评分标准的步骤

### 1. 打开配置文件

编辑项目根目录下的 `preset_criteria.json` 文件。

### 2. 添加评分标准配置

在JSON文件中添加一个新的评分标准对象，格式如下：

```json
{
  "标准ID": {
    "id": "标准ID（与key相同）",
    "name": "评分标准名称",
    "description": "评分标准简要说明",
    "prompt": "详细的评分指导说明（用于指导Gemini如何评分）",
    "weight": 权重值（数字，如 1.0、1.2）
  }
}
```

### 3. 完整示例

```json
{
  "courage": {
    "id": "courage",
    "name": "开口勇气/主动表达",
    "description": "评估孩子主动开口、尝试表达的意愿和勇气",
    "prompt": "请从以下维度评估孩子的开口勇气（1-10分）：\n1. 主动开口意愿：孩子是否主动发起对话，而非仅被动回应\n2. 主动提问频率：是否用英语主动提出问题（如Why, What, How等）\n3. 新词尝试勇气：是否敢于尝试使用新词汇或短句，即使可能不完全正确\n\n评分标准：\n- 9-10分：频繁主动开口，敢于尝试新表达\n- 7-8分：多次主动表达，偶尔尝试新词\n- 5-6分：偶有主动，但多为被动回应\n- 3-4分：很少主动，基本被动回应\n- 1-2分：几乎不主动，沉默时间长",
    "weight": 1.2
  },
  "pronunciation": {
    "id": "pronunciation",
    "name": "发音清晰度",
    "description": "评估孩子的发音准确性和清晰程度",
    "prompt": "请从以下维度评估孩子的发音（1-10分）：\n1. 元音发音：元音是否清晰准确\n2. 辅音发音：辅音（特别是th, r, l等）是否正确\n3. 重音位置：单词重音是否基本正确\n4. 整体清晰度：是否容易听懂\n\n评分标准：\n- 9-10分：发音清晰准确，几乎无错误\n- 7-8分：发音较好，偶有小错但不影响理解\n- 5-6分：发音基本可懂，但有明显错误\n- 3-4分：发音错误较多，理解有困难\n- 1-2分：发音不清，难以理解",
    "weight": 1.0
  }
}
```

## 🔍 字段说明

| 字段 | 类型 | 必填 | 说明 |
|------|------|------|------|
| `id` | String | ✅ | 评分标准的唯一标识符（建议使用英文） |
| `name` | String | ✅ | 评分标准的显示名称 |
| `description` | String | ✅ | 评分标准的简要说明（50字内） |
| `prompt` | String | ✅ | **最重要**：详细的评分指导说明，用于指导AI如何评分 |
| `weight` | Number | ⭕ | 权重值（默认1.0），用于未来加权计算 |

## 📐 编写高质量的 Prompt

### 结构建议

1. **开场说明**：明确评分范围（如：1-10分）
2. **评估维度**：列出3-5个具体的评估维度
3. **评分标准**：提供清晰的分数档位说明

### 示例模板

```
请从以下维度评估孩子的[标准名称]（1-10分）：
1. [维度1]：[具体说明]
2. [维度2]：[具体说明]
3. [维度3]：[具体说明]
4. [维度4]：[具体说明]
5. [维度5]：[具体说明]

评分标准：
- 9-10分：[优秀表现的具体描述]
- 7-8分：[良好表现的具体描述]
- 5-6分：[中等表现的具体描述]
- 3-4分：[较差表现的具体描述]
- 1-2分：[很差表现的具体描述]
```

## 🎨 现有内置评分标准（评价AI表现）

1. **鼓励开口能力** (encourage_speaking)
   - 评估AI是否能有效鼓励孩子主动开口说英语

2. **互动吸引力** (interactive_engagement)
   - 评估AI回复是否能吸引孩子注意力，引发继续对话的兴趣

3. **提问引导能力** (question_guidance)
   - 评估AI是否能通过有效提问引导孩子思考和表达

4. **词汇拓展引导** (vocabulary_expansion)
   - 评估AI是否能有效引导和帮助孩子拓展词汇量

5. **句式引导能力** (sentence_pattern_guidance)
   - 评估AI是否能引导孩子使用更丰富的句式结构

6. **错误纠正技巧** (error_correction)
   - 评估AI是否能温和有效地纠正孩子的语法错误

7. **话题连贯性** (topic_coherence)
   - 评估AI回复是否与上下文连贯，能否维持话题发展

8. **情感支持表达** (emotional_support)
   - 评估AI是否能提供情感支持，让孩子感到被理解和关心

9. **回复丰富度** (response_richness)
   - 评估AI回复是否内容丰富，有细节和描述

10. **创意激发能力** (creativity_stimulation)
    - 评估AI是否能激发孩子的想象力和创造性思维

11. **年龄适配度** (age_appropriateness)
    - 评估AI回复是否适合孩子的年龄特点和认知水平

12. **耐心等待能力** (patience_waiting)
    - 评估AI是否能耐心等待孩子思考和组织语言

13. **教学效果** (teaching_effectiveness)
    - 评估AI是否能有效传递知识，帮助孩子学习和成长

## 🔄 应用更改

添加或修改评分标准后：

1. **无需重启应用**（下次刷新页面时自动加载）
2. 或者手动刷新浏览器页面（F5）
3. 新标准会自动出现在"快速添加内置标准"下拉菜单中

## ⚠️ 注意事项

1. **JSON格式**：确保JSON格式正确，注意逗号和引号
2. **唯一ID**：每个评分标准的ID必须唯一
3. **prompt字段**：这是最重要的字段，决定了评分质量
4. **换行符**：在JSON中使用`\n`表示换行
5. **逗号问题**：JSON对象中最后一项后面**不要**加逗号
6. **转义字符**：如果prompt中有引号，需要使用`\"`转义

## ✅ 验证配置

可以使用在线JSON验证工具检查格式：
- https://jsonlint.com/
- 或者使用VSCode的JSON格式化功能（Shift + Alt + F）

## 💡 评分标准设计最佳实践

### 1. 可观察性
- 确保评分维度是可以观察和量化的
- 避免过于主观或模糊的标准

### 2. 年龄适配性
- 考虑孩子的年龄特点
- 不同年龄段可以有不同的评分标准

### 3. 具体化
- 避免"表现好"、"做得不错"等模糊描述
- 使用具体的行为描述（如"使用3个以上新词汇"）

### 4. 一致性
- 同一档位的描述应该在所有标准中保持一致的水平
- 9-10分应该代表"优秀"，而不是"完美"

### 5. 平衡性
- 不要设计过于严格或过于宽松的标准
- 大多数孩子应该能在5-7分的范围内

## 🎯 示例：添加新标准

假设我们要添加"发音清晰度"标准：

1. 打开 `preset_criteria.json`
2. 在文件末尾（最后一个标准的`}`后面）添加逗号
3. 添加新标准：

```json
,
"pronunciation": {
  "id": "pronunciation",
  "name": "发音清晰度",
  "description": "评估孩子的英语发音准确性和清晰程度",
  "prompt": "请从以下维度评估孩子的发音（1-10分）：\n1. 元音发音：元音是否清晰准确\n2. 辅音发音：辅音是否正确\n3. 重音位置：单词重音是否正确\n4. 语调自然度：句子语调是否自然\n5. 整体清晰度：是否容易听懂\n\n评分标准：\n- 9-10分：发音清晰准确，近乎母语水平\n- 7-8分：发音较好，偶有小错但不影响理解\n- 5-6分：发音基本可懂，但有明显口音或错误\n- 3-4分：发音错误较多，理解需要费力\n- 1-2分：发音不清，很难理解",
  "weight": 1.0
}
```

4. 保存文件
5. 刷新浏览器页面
6. 在下拉菜单中选择"⭐ 发音清晰度"

---

**文件位置**：`d:\test_agent\preset_criteria.json`  
**API端点**：`/api/preset-criteria`  
**最后更新**：2025-10-18

